# app.py
import os, io, re, json, uuid, base64, tempfile
import requests, streamlit as st, boto3
from typing import List, Tuple, Optional, Dict
from PIL import Image, ImageOps, ImageFile

ImageFile.LOAD_TRUNCATED_IMAGES = True

# ===== Env (Fidealis) =====
API_URL = os.getenv("API_URL")
API_KEY = os.getenv("API_KEY")
ACCOUNT_KEY = os.getenv("ACCOUNT_KEY")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# ===== Env (Cloudflare R2) =====
R2_ACCOUNT_ID = os.getenv("R2_ACCOUNT_ID")
R2_ACCESS_KEY_ID = os.getenv("R2_ACCESS_KEY_ID")
R2_SECRET_ACCESS_KEY = os.getenv("R2_SECRET_ACCESS_KEY")
R2_BUCKET = os.getenv("R2_BUCKET")
R2_REGION = os.getenv("R2_REGION", "auto")
R2_ENDPOINT = f"https://{R2_ACCOUNT_ID}.r2.cloudflarestorage.com"

# ===== Clients =====
s3 = boto3.client(
    "s3",
    region_name=R2_REGION,
    endpoint_url=R2_ENDPOINT,
    aws_access_key_id=R2_ACCESS_KEY_ID,
    aws_secret_access_key=R2_SECRET_ACCESS_KEY,
)

IMG_EXTS = {".jpg",".jpeg",".png",".JPG",".JPEG",".PNG"}
CLIENT_RE = re.compile(r"^\s*(.+?)\s*-\s*(.+?)\s*$")

# ---------- Fidealis ----------
def api_login() -> Optional[str]:
    try:
        r = requests.get(API_URL, params={"key":API_KEY,"call":"loginUserFromAccountKey","accountKey":ACCOUNT_KEY}, timeout=30)
        r.raise_for_status()
        return r.json().get("PHPSESSID")
    except Exception:
        return None

def api_upload_files(description: str, filepaths: List[str], session_id: str):
    for i in range(0, len(filepaths), 12):
        batch = filepaths[i:i+12]
        data = {
            "key": API_KEY, "PHPSESSID": session_id, "call": "setDeposit",
            "description": description, "type":"deposit","hidden":"0","sendmail":"1","background":"2"
        }
        for idx, fp in enumerate(batch, start=1):
            with open(fp, "rb") as f:
                data[f"file{idx}"] = base64.b64encode(f.read()).decode("utf-8")
            data[f"filename{idx}"] = os.path.basename(fp)
        requests.post(API_URL, data=data, timeout=60)

def get_credit(session_id: str):
    try:
        r = requests.get(API_URL, params={"key":API_KEY,"PHPSESSID":session_id,"call":"getCredits","product_ID":""}, timeout=30)
        if r.status_code==200: return r.json()
    except Exception: pass
    return None

def get_quantity_for_product_4(credit_data):
    try: return credit_data["4"]["quantity"]
    except Exception: return "N/A"

# ---------- Geocoding ----------
def get_coordinates(address: str) -> Tuple[Optional[float], Optional[float]]:
    if not GOOGLE_API_KEY: return None, None
    try:
        r = requests.get("https://maps.googleapis.com/maps/api/geocode/json",
                         params={"address":address,"key":GOOGLE_API_KEY}, timeout=30)
        r.raise_for_status()
        data = r.json()
        if data.get("status")=="OK" and data.get("results"):
            loc = data["results"][0]["geometry"]["location"]
            return loc["lat"], loc["lng"]
    except Exception: pass
    return None, None

# ---------- Images ----------
def preprocess_to_jpeg_bytes(raw: bytes, max_dim=1600, quality=80) -> bytes:
    with Image.open(io.BytesIO(raw)) as img:
        img = ImageOps.exif_transpose(img)
        if img.mode not in ("RGB","L"): img = img.convert("RGB")
        w,h = img.size
        s = min(1.0, max_dim/max(w,h))
        if s < 1.0:
            img = img.resize((int(w*s), int(h*s)), Image.LANCZOS)
        out = io.BytesIO()
        img.save(out, "JPEG", quality=quality, optimize=True)
        return out.getvalue()

def create_collage(pil_images: List[Image.Image], out_path: str, quality=80):
    min_h = min(i.size[1] for i in pil_images)
    resized = [ImageOps.fit(i, (int(i.size[0]*min_h/i.size[1]), min_h)) for i in pil_images]
    total_w = sum(i.size[0] for i in resized) + (len(resized)-1)*20 + 50
    canvas = Image.new("RGB", (total_w, min_h+50), (255,255,255))
    x = 25
    for i in resized:
        canvas.paste(i, (x,25)); x += i.size[0] + 20
    canvas.save(out_path, "JPEG", quality=quality, optimize=True)
    canvas.close()
    for i in pil_images: i.close()

def create_all_collages(filepaths: List[str], client_name: str, workdir: str, max_dim=1600, q=80) -> List[str]:
    out = []
    for i in range(0, len(filepaths), 3):
        group = filepaths[i:i+3]
        imgs=[]
        for fp in group:
            with open(fp,"rb") as f: jb = preprocess_to_jpeg_bytes(f.read(), max_dim=max_dim, quality=q)
            imgs.append(Image.open(io.BytesIO(jb)))
        p = os.path.join(workdir, f"c_{client_name}_{len(out)+1}.jpg")
        create_collage(imgs, p, quality=q)
        out.append(p)
    if out:
        renamed = os.path.join(workdir, f"{client_name}_1.jpg")
        os.replace(out[0], renamed); out[0] = renamed
    return out

# ---------- R2 util ----------
def r2_presign_post_for_prefix(prefix: str, max_mb=2048, expires=3600):
    return s3.generate_presigned_post(
        Bucket=R2_BUCKET,
        Key=prefix + "${filename}",
        Fields={"Content-Type":"application/octet-stream"},
        Conditions=[
            ["starts-with","$key",prefix],
            ["starts-with","$Content-Type",""],
            ["content-length-range", 1, max_mb*1024*1024],
        ],
        ExpiresIn=expires,
    )

def list_objects(prefix: str) -> List[str]:
    keys, token = [], None
    while True:
        kw={"Bucket":R2_BUCKET,"Prefix":prefix,"MaxKeys":1000}
        if token: kw["ContinuationToken"]=token
        resp = s3.list_objects_v2(**kw)
        for obj in resp.get("Contents", []):
            keys.append(obj["Key"])
        if resp.get("IsTruncated"): token = resp.get("NextContinuationToken")
        else: break
    return keys

def split_client(folder: str) -> Optional[Tuple[str,str]]:
    m = CLIENT_RE.match(folder)
    return (m.group(1).strip(), m.group(2).strip()) if m else None

def group_by_client(keys: List[str], batch_prefix: str) -> Dict[str,List[str]]:
    groups: Dict[str,List[str]] = {}
    for k in keys:
        if not k.startswith(batch_prefix) or k.endswith("/"): continue
        rel = k[len(batch_prefix):]                  # "<Client - Address>/.../file.jpg"
        top = rel.split("/",1)[0]                    # "<Client - Address>"
        if split_client(top):
            groups.setdefault(top, []).append(k)
    for v in groups.values(): v.sort()
    return groups

# ========== UI ==========
st.set_page_config(page_title="FIDEALIS â€” Upload dossier â†’ R2 â†’ Traitement auto", layout="centered")
st.title("FIDEALIS â€” Dossier â†’ R2 (auto) â†’ Collages â†’ DÃ©pÃ´t")

session_id = api_login()
if not session_id:
    st.error("Connexion Fidealis Ã©chouÃ©e (API_URL/API_KEY/ACCOUNT_KEY).")
    st.stop()

credits = get_credit(session_id)
if isinstance(credits, dict):
    st.caption(f"CrÃ©dit restant (Produit 4) : {get_quantity_for_product_4(credits)}")

with st.expander("Options de traitement"):
    max_dim = st.slider("Dimension max (px) avant collage", 800, 4000, 1600, step=100)
    jpeg_q  = st.slider("QualitÃ© JPEG", 50, 95, 80, step=1)

# ------------- MODE 1 : dÃ©clenchÃ© par ?batch=... (post-upload) -------------
params = st.query_params
if "batch" in params:
    batch_id = params["batch"]
    batch_prefix = f"uploads/{batch_id}/"
    st.info(f"Traitement en cours pour le batch : {batch_id}")
    keys = list_objects(batch_prefix)
    st.write(f"{len(keys)} fichiers dÃ©tectÃ©s dans R2.")
    groups = group_by_client(keys, batch_prefix)
    if not groups:
        st.error("Aucun dossier client `ClientName - Address` dÃ©tectÃ© sous ce batch.")
        st.stop()

    st.write(f"ðŸ‘¥ {len(groups)} client(s) dÃ©tectÃ©(s).")
    p_clients = st.progress(0.0)

    for idx, (client_folder, client_keys) in enumerate(groups.items(), start=1):
        parsed = split_client(client_folder)
        if not parsed:
            p_clients.progress(idx/len(groups)); continue
        client_name, address = parsed
        lat, lng = get_coordinates(address)
        if lat is None or lng is None:
            lat, lng = ("N/A","N/A")
            st.warning(f"GÃ©ocodage indisponible : {client_folder}")

        st.info(f"ðŸ‘¤ {client_name} â€” {len(client_keys)} fichier(s)")
        with tempfile.TemporaryDirectory(dir="/tmp") as tmpdir:
            normalized: List[str] = []
            p_imgs = st.progress(0.0)
            for j, key in enumerate(client_keys, start=1):
                buf = io.BytesIO()
                s3.download_fileobj(R2_BUCKET, key, buf)
                jb = preprocess_to_jpeg_bytes(buf.getvalue(), max_dim=max_dim, quality=jpeg_q)
                outp = os.path.join(tmpdir, f"{client_name}_{j:05d}.jpg")
                with open(outp,"wb") as o: o.write(jb)
                normalized.append(outp)
                p_imgs.progress(j/len(client_keys))

            collages = create_all_collages(normalized, client_name, tmpdir, max_dim=max_dim, q=jpeg_q)
            description = (f"SCELLÃ‰ NUMERIQUE BÃ©nÃ©ficiaire: Nom: {client_name}, "
                           f"Adresse: {address}, CoordonnÃ©es GPS: Latitude {lat}, Longitude {lng}")
            api_upload_files(description, collages, session_id)
        st.success(f"âœ… {client_name} â€” {len(collages)} collage(s) envoyÃ©(s).")
        p_clients.progress(idx/len(groups))
    st.balloons(); st.success("ðŸŽ‰ Batch terminÃ©.")
    st.stop()

# ------------- MODE 2 : Ã©cran initial (un seul bouton) -------------
st.markdown("### 1 clic : choisir le dossier et **Soumettre**")
if st.button("SÃ©lectionner un dossier et Soumettre", type="primary"):
    # 1) crÃ©er un batch + presign Â« starts-with Â»
    batch_id = str(uuid.uuid4())
    prefix = f"uploads/{batch_id}/"
    post = r2_presign_post_for_prefix(prefix, max_mb=2048, expires=3600)

    # 2) injecter un composant HTML qui :
    #    - ouvre un sÃ©lecteur de dossier (webkitdirectory)
    #    - uploade **tous** les fichiers en parallÃ¨le vers R2 (clÃ© = prefix + chemin relatif)
    #    - Ã  la fin â†’ redirige la page vers ?batch=<batch_id> (le serveur traitera automatiquement)
    st.components.v1.html(f"""
<!doctype html><html><body>
<input id="picker" type="file" webkitdirectory directory multiple style="display:none" />
<button id="go" style="padding:10px 16px;font-size:16px;">Choisir le dossierâ€¦</button>
<pre id="log" style="white-space:pre-wrap;border:1px solid #eee;padding:8px;border-radius:6px;max-height:240px;overflow:auto;margin-top:10px;"></pre>
<script>
const pres = {json.dumps(post)};
const prefix = {json.dumps(prefix)};
const log = (m)=>document.getElementById('log').textContent += m + "\\n";

const pick = document.getElementById('picker');
document.getElementById('go').addEventListener('click', ()=> pick.click());

function keyFor(rel) {{
  return (prefix + rel.replace(/^\\.\\//,'').replaceAll('\\\\','/'));
}}

async function uploadOne(file, relPath) {{
  const key = keyFor(relPath);
  const form = new FormData();
  Object.entries(pres.fields).forEach(([k,v])=>form.append(k,v));
  form.append('key', key);
  form.append('Content-Type', file.type || 'application/octet-stream');
  form.append('file', file);
  const t0 = performance.now();
  const res = await fetch(pres.url, {{ method:'POST', body: form }});
  const dt = ((performance.now()-t0)/1000).toFixed(2);
  if (!res.ok) throw new Error(`HTTP ${{res.status}}`);
  log(`OK ${'{'}relPath{'}'} â†’ ${'{'}key{'}'} (${ '{'}dt{'}'}s)`);
}}

pick.addEventListener('change', async (ev) => {{
  const files = Array.from(pick.files||[]);
  if (!files.length) {{ log("Aucun fichier sÃ©lectionnÃ©."); return; }}

  // Limiter aux extensions images seulement (serveur re-filtrera aussi)
  const allowed = new Set([".jpg",".jpeg",".png",".JPG",".JPEG",".PNG"]);
  const items = files
    .map(f=>{{ const rel=f.webkitRelativePath||f.name;
               const ext=rel.slice(rel.lastIndexOf('.'));
               return {{file:f, rel, ext}}; }})
    .filter(x=> allowed.has(x.ext));

  if (!items.length) {{ log("Aucune image dÃ©tectÃ©e dans le dossier."); return; }}

  log(`Fichiers dÃ©tectÃ©s: ${{items.length}} â€” upload en parallÃ¨leâ€¦`);
  const K = 8; // parallÃ©lisme
  const q = items.slice();
  let done=0;
  const worker = async ()=>{{
    while(q.length){{
      const it=q.shift();
      try {{ await uploadOne(it.file, it.rel); }}
      catch(e) {{ log("FAIL "+it.rel+" :: "+e.message); }}
      done++; if (done%10===0) log(`... ${{done}}/${{items.length}}`);
    }}
  }};
  await Promise.all(Array.from({{length:K}}, worker));
  // Rediriger vers ?batch=<id> pour lancer le traitement cÃ´tÃ© serveur
  window.location.search = "?batch=" + {json.dumps(batch_id)};
}});
</script>
</body></html>
""", height=320)
    st.stop()
