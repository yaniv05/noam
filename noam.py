# app.py
import os, io, re, json, uuid, base64, tempfile, math
import requests, streamlit as st, boto3
from typing import List, Tuple, Optional, Dict, Callable
from PIL import Image, ImageOps, ImageFile
import botocore.client

ImageFile.LOAD_TRUNCATED_IMAGES = True

# ========= ENV (Fidealis) =========
API_URL = os.getenv("API_URL")
API_KEY = os.getenv("API_KEY")
ACCOUNT_KEY = os.getenv("ACCOUNT_KEY")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# ========= ENV (Cloudflare R2) =========
R2_ACCOUNT_ID = os.getenv("R2_ACCOUNT_ID")           # ex: f02b01cf197682b810e6a39fdbcbaad3
R2_BUCKET = os.getenv("R2_BUCKET")                   # ex: fidealis-demo
R2_ACCESS_KEY_ID = os.getenv("R2_ACCESS_KEY_ID")
R2_SECRET_ACCESS_KEY = os.getenv("R2_SECRET_ACCESS_KEY")
R2_REGION = os.getenv("R2_REGION", "auto")

# Virtual-hosted style (navigateur) + endpoint SDK (serveur)
R2_BUCKET_HOST = f"{R2_BUCKET}.{R2_ACCOUNT_ID}.r2.cloudflarestorage.com"
R2_ENDPOINT = f"https://{R2_ACCOUNT_ID}.r2.cloudflarestorage.com"

# ========= boto3 client =========
s3 = boto3.client(
    "s3",
    region_name=R2_REGION,
    endpoint_url=R2_ENDPOINT,
    aws_access_key_id=R2_ACCESS_KEY_ID,
    aws_secret_access_key=R2_SECRET_ACCESS_KEY,
    config=botocore.client.Config(s3={"addressing_style": "virtual"})
)

IMG_EXTS = {".jpg",".jpeg",".png",".JPG",".JPEG",".PNG"}
CLIENT_RE = re.compile(r"^\s*(.+?)\s*-\s*(.+?)\s*$")

# ---------- Fidealis ----------
def api_login() -> Optional[str]:
    try:
        r = requests.get(API_URL, params={"key":API_KEY,"call":"loginUserFromAccountKey","accountKey":ACCOUNT_KEY}, timeout=30)
        r.raise_for_status()
        return r.json().get("PHPSESSID")
    except Exception:
        return None

def api_upload_files(
    description: str,
    filepaths: List[str],
    session_id: str,
    log: Optional[Callable[[str], None]] = None,
    progress_cb: Optional[Callable[[int, int], None]] = None
):
    """
    Envoi √† Fidealis par lots de 12 avec progression.
    """
    total_batches = math.ceil(len(filepaths) / 12) if filepaths else 0
    for b_idx, i in enumerate(range(0, len(filepaths), 12), start=1):
        batch = filepaths[i:i+12]
        data = {
            "key": API_KEY, "PHPSESSID": session_id, "call": "setDeposit",
            "description": description, "type":"deposit","hidden":"0","sendmail":"1","background":"2"
        }

        if log:
            log(f"üì¶ Lot {b_idx}/{total_batches} ‚Üí {len(batch)} fichier(s) : " +
                ", ".join(os.path.basename(x) for x in batch))

        for idx, fp in enumerate(batch, start=1):
            with open(fp, "rb") as f:
                data[f"file{idx}"] = base64.b64encode(f.read()).decode("utf-8")
            data[f"filename{idx}"] = os.path.basename(fp)

        # POST
        r = requests.post(API_URL, data=data, timeout=60)
        if log:
            if r.ok:
                log(f"‚úÖ Lot {b_idx} OK (HTTP {r.status_code})")
            else:
                log(f"‚ùå Lot {b_idx} FAIL (HTTP {r.status_code}) ‚Äî body: {r.text[:200]}")

        if progress_cb:
            progress_cb(b_idx, total_batches)

def get_credit(session_id: str):
    try:
        r = requests.get(API_URL, params={"key":API_KEY,"PHPSESSID":session_id,"call":"getCredits","product_ID":""}, timeout=30)
        if r.status_code==200: return r.json()
    except Exception: pass
    return None

def get_quantity_for_product_4(credit_data):
    try: return credit_data["4"]["quantity"]
    except Exception: return "N/A"

# ---------- Geocoding ----------
def get_coordinates(address: str) -> Tuple[Optional[float], Optional[float]]:
    if not GOOGLE_API_KEY: return None, None
    try:
        r = requests.get("https://maps.googleapis.com/maps/api/geocode/json",
                         params={"address":address,"key":GOOGLE_API_KEY}, timeout=30)
        r.raise_for_status()
        data = r.json()
        if data.get("status")=="OK" and data.get("results"):
            loc = data["results"][0]["geometry"]["location"]
            return loc["lat"], loc["lng"]
    except Exception: pass
    return None, None

# ---------- Images ----------
def preprocess_to_jpeg_bytes(raw: bytes, max_dim=1600, quality=80) -> bytes:
    with Image.open(io.BytesIO(raw)) as img:
        img = ImageOps.exif_transpose(img)
        if img.mode not in ("RGB","L"): img = img.convert("RGB")
        w,h = img.size
        s = min(1.0, max_dim/max(w,h))
        if s < 1.0:
            img = img.resize((int(w*s), int(h*s)), Image.LANCZOS)
        out = io.BytesIO()
        img.save(out, "JPEG", quality=quality, optimize=True)
        return out.getvalue()

def create_collage(pil_images: List[Image.Image], out_path: str, quality=80):
    min_h = min(i.size[1] for i in pil_images)
    resized = [ImageOps.fit(i, (int(i.size[0]*min_h/i.size[1]), min_h)) for i in pil_images]
    total_w = sum(i.size[0] for i in resized) + (len(resized)-1)*20 + 50
    canvas = Image.new("RGB", (total_w, min_h+50), (255,255,255))
    x = 25
    for i in resized:
        canvas.paste(i, (x,25)); x += i.size[0] + 20
    canvas.save(out_path, "JPEG", quality=quality, optimize=True)
    canvas.close()
    for i in pil_images: i.close()

def create_all_collages(filepaths: List[str], client_name: str, workdir: str, max_dim=1600, q=80) -> List[str]:
    out = []
    for i in range(0, len(filepaths), 3):
        group = filepaths[i:i+3]
        imgs=[]
        for fp in group:
            with open(fp,"rb") as f:
                jb = preprocess_to_jpeg_bytes(f.read(), max_dim=max_dim, quality=q)
            imgs.append(Image.open(io.BytesIO(jb)))
        p = os.path.join(workdir, f"c_{client_name}_{len(out)+1}.jpg")
        create_collage(imgs, p, quality=q)
        out.append(p)
    if out:
        renamed = os.path.join(workdir, f"{client_name}_1.jpg")
        os.replace(out[0], renamed); out[0] = renamed
    return out

# ---------- R2 (serveur) ----------
def list_objects(prefix: str) -> List[str]:
    keys, token = [], None
    while True:
        kw={"Bucket":R2_BUCKET,"Prefix":prefix,"MaxKeys":1000}
        if token: kw["ContinuationToken"]=token
        resp = s3.list_objects_v2(**kw)
        for obj in resp.get("Contents", []):
            keys.append(obj["Key"])
        if resp.get("IsTruncated"): token = resp.get("NextContinuationToken")
        else: break
    return keys

def split_client(folder: str) -> Optional[Tuple[str,str]]:
    m = CLIENT_RE.match(folder)
    return (m.group(1).strip(), m.group(2).strip()) if m else None

def find_client_segment(path_rel: str) -> Optional[str]:
    parts = path_rel.strip("/").split("/")
    for seg in parts:
        if CLIENT_RE.match(seg or ""):
            return seg
    return None

def group_by_client(keys: List[str], batch_prefix: str) -> Dict[str,List[str]]:
    groups: Dict[str,List[str]] = {}
    samples = []
    for k in keys:
        if not k.startswith(batch_prefix) or k.endswith("/"):
            continue
        rel = k[len(batch_prefix):]            # tout ce qui vient apr√®s uploads/<batch>/
        if not samples and rel:
            samples.append(rel)
        client_seg = find_client_segment(rel)
        if client_seg:
            groups.setdefault(client_seg, []).append(k)
    for v in groups.values():
        v.sort()
    if not groups and samples:
        st.warning(f"Exemple de chemin relatif (pour debug) : {samples[0]}")
    return groups

# ---------- Diagnostic R2 ----------
def r2_health():
    st.subheader("üîç Diagnostic R2")
    st.write("Bucket host (browser):", R2_BUCKET_HOST)
    st.write("Endpoint (SDK):", R2_ENDPOINT)
    try:
        s3.head_bucket(Bucket=R2_BUCKET)
        st.success("head_bucket ‚úÖ")
    except Exception as e:
        st.error(f"head_bucket ‚ùå : {e}")

    # Test PUT/GET serveur
    try:
        test_key = f"diagnostics/{uuid.uuid4()}-ping.txt"
        s3.put_object(Bucket=R2_BUCKET, Key=test_key, Body=b"ping")
        obj = s3.get_object(Bucket=R2_BUCKET, Key=test_key)
        body = obj["Body"].read()
        st.success(f"PUT/GET serveur ‚úÖ ({body!r})")
        s3.delete_object(Bucket=R2_BUCKET, Key=test_key)
    except Exception as e:
        st.error(f"PUT/GET serveur ‚ùå : {e}")

# ========== UI ==========
st.set_page_config(page_title="FIDEALIS ‚Äî Dossier ‚Üí R2 ‚Üí Traitement auto", layout="centered")
st.title("FIDEALIS ‚Äî Dossier ‚Üí R2 (auto) ‚Üí Collages ‚Üí D√©p√¥t")

session_id = api_login()
if not session_id:
    st.error("Connexion Fidealis √©chou√©e (API_URL/API_KEY/ACCOUNT_KEY).")
    st.stop()

credits = get_credit(session_id)
if isinstance(credits, dict):
    st.caption(f"Cr√©dit restant (Produit 4) : {get_quantity_for_product_4(credits)}")

with st.expander("üß™ Diagnostic R2", expanded=False):
    r2_health()

with st.expander("Options de traitement"):
    max_dim = st.slider("Dimension max (px) avant collage", 800, 4000, 1600, step=100)
    jpeg_q  = st.slider("Qualit√© JPEG", 50, 95, 80, step=1)

# --- Query params ---
try:
    params = st.query_params
except Exception:
    params = st.experimental_get_query_params()

# --- Mode post-upload (?batch=...) ---
if "batch" in params:
    batch_id = params["batch"] if isinstance(params["batch"], str) else params["batch"][0]
    batch_prefix = f"uploads/{batch_id}/"
    st.info(f"Traitement en cours pour le batch : {batch_id}")

    keys = list_objects(batch_prefix)
    st.write(f"üì¶ {len(keys)} fichier(s) d√©tect√©(s) dans R2 sous {batch_prefix}")
    groups = group_by_client(keys, batch_prefix)
    if not groups:
        st.error("Aucun dossier client `ClientName - Address` d√©tect√© sous ce batch.")
        st.stop()

    st.write(f"üë• {len(groups)} client(s) d√©tect√©(s).")
    p_clients = st.progress(0.0)

    for idx, (client_folder, client_keys) in enumerate(groups.items(), start=1):
        parsed = split_client(client_folder)
        if not parsed:
            p_clients.progress(idx/len(groups)); continue
        client_name, address = parsed
        lat, lng = get_coordinates(address)
        if lat is None or lng is None:
            lat, lng = ("N/A","N/A")
            st.warning(f"G√©ocodage indisponible : {client_folder}")

        st.subheader(f"üë§ {client_name}")
        st.caption(f"{len(client_keys)} image(s)")

        with tempfile.TemporaryDirectory(dir="/tmp") as tmpdir:
            # Progression normalisation d'images
            p_imgs = st.progress(0.0)
            normalized: List[str] = []
            for j, key in enumerate(client_keys, start=1):
                buf = io.BytesIO()
                s3.download_fileobj(R2_BUCKET, key, buf)
                jb = preprocess_to_jpeg_bytes(buf.getvalue(), max_dim=max_dim, quality=jpeg_q)
                outp = os.path.join(tmpdir, f"{client_name}_{j:05d}.jpg")
                with open(outp,"wb") as o: o.write(jb)
                normalized.append(outp)
                p_imgs.progress(j/len(client_keys))

            # Collages
            st.caption("Cr√©ation des collages‚Ä¶")
            collages = create_all_collages(normalized, client_name, tmpdir, max_dim=max_dim, q=jpeg_q)
            st.success(f"{len(collages)} collage(s) cr√©√©(s)")

            # Envoi Fidealis avec progression par lot
            st.caption("Envoi √† Fidealis (lots de 12)‚Ä¶")
            p_batches = st.progress(0.0)
            log_area = st.empty()

            def log_line(msg: str):
                prev = log_area.text_area if hasattr(log_area, "last") else ""
                # simple append sans relire : on garde en m√©moire la derni√®re concat
                log_area.last = (getattr(log_area, "last", "") + msg + "\n")
                log_area.text_area("Logs d‚Äôenvoi Fidealis", value=log_area.last, height=160)

            def p_cb(done: int, total: int):
                p_batches.progress(done/total if total else 1.0)

            api_upload_files(
                description=(f"SCELL√â NUMERIQUE B√©n√©ficiaire: Nom: {client_name}, "
                             f"Adresse: {address}, Coordonn√©es GPS: Latitude {lat}, Longitude {lng}"),
                filepaths=collages,
                session_id=session_id,
                log=log_line,
                progress_cb=p_cb
            )

        st.success(f"‚úÖ {client_name} ‚Äî {len(collages)} collage(s) envoy√©(s).")
        p_clients.progress(idx/len(groups))

    st.balloons(); st.success("üéâ Batch termin√©.")
    st.stop()

# --- Ecran initial : upload -> R2 (PUT sign√©) ---
st.markdown("### 1 clic : choisir le dossier et **Soumettre**")
st.caption("S√©lectionne le dossier racine (qui contient les sous-dossiers `ClientName - Address`).")
if st.button("S√©lectionner un dossier et Soumettre", type="primary"):
    if not all([R2_ACCOUNT_ID, R2_BUCKET, R2_ACCESS_KEY_ID, R2_SECRET_ACCESS_KEY]):
        st.error("R2 env manquantes (ACCOUNT_ID/BUCKET/ACCESS_KEY/SECRET).")
        st.stop()

    batch_id = str(uuid.uuid4())
    prefix = f"uploads/{batch_id}/"

    st.components.v1.html(f"""
<!doctype html><html>
<body>
<input id="picker" type="file" webkitdirectory directory multiple style="display:none" />
<button id="go" style="padding:10px 16px;font-size:16px;">Choisir le dossier‚Ä¶</button>

<div style="margin-top:10px;">
  <progress id="prog" value="0" max="100" style="width:100%;height:16px;"></progress>
  <div id="pc" style="font:12px sans-serif;margin-top:4px;">0%</div>
</div>

<pre id="log" style="white-space:pre-wrap;border:1px solid #eee;padding:8px;border-radius:6px;max-height:220px;overflow:auto;margin-top:10px;"></pre>

<script type="module">
import {{ AwsClient }} from "https://esm.sh/aws4fetch@1.0.17";

const ACCESS_KEY_ID = {json.dumps(R2_ACCESS_KEY_ID)};
const SECRET_ACCESS_KEY = {json.dumps(R2_SECRET_ACCESS_KEY)};
const ACCOUNT_ID = {json.dumps(R2_ACCOUNT_ID)};
const BUCKET = {json.dumps(R2_BUCKET)};
const BUCKET_HOST = `${{BUCKET}}.${{ACCOUNT_ID}}.r2.cloudflarestorage.com`;
const PREFIX = {json.dumps(prefix)};
const BATCH_ID = {json.dumps(batch_id)};

const client = new AwsClient({{
  accessKeyId: ACCESS_KEY_ID,
  secretAccessKey: SECRET_ACCESS_KEY,
  service: "s3",
  region: "auto"
}});

const log = (m)=>document.getElementById('log').textContent += m + "\\n";
const pick = document.getElementById('picker');
const bar = document.getElementById('prog');
const pc  = document.getElementById('pc');

document.getElementById('go').addEventListener('click', ()=> pick.click());

function normRelPath(rel) {{
  return rel.replace(/^\\.\\//,'').replaceAll('\\\\','/'); // Windows ‚Üí /
}}
function keyFor(rel) {{
  return PREFIX + normRelPath(rel);
}}

function upd(i, n){{
  const pct = Math.round((i*100)/n);
  bar.value = pct; pc.textContent = pct + "%";
}}

pick.addEventListener('change', async () => {{
  const files = Array.from(pick.files||[]);
  if (!files.length) {{ log("Aucun fichier s√©lectionn√©."); return; }}

  const allowed = new Set([".jpg",".jpeg",".png",".JPG",".JPEG",".PNG"]);
  const items = files
    .map(f=>{{ const rel=f.webkitRelativePath||f.name;
               const ext=rel.slice(rel.lastIndexOf('.'));
               return {{file:f, rel, ext}}; }})
    .filter(x=> allowed.has(x.ext));

  if (!items.length) {{ log("Aucune image d√©tect√©e dans le dossier."); return; }}
  log(`Fichiers d√©tect√©s: ${{items.length}} ‚Äî upload en parall√®le (PUT sign√©)‚Ä¶`);

  const K = 8; // parall√©lisme
  const queue = items.slice();
  let done=0, ko=0;

  async function uploadOne(it) {{
    const url = `https://${{BUCKET_HOST}}/${{keyFor(it.rel)}}`;
    const t0 = performance.now();
    const res = await client.fetch(url, {{
      method: "PUT",
      body: it.file,
      headers: {{ "Content-Type": it.file.type || "application/octet-stream" }}
    }});
    const dt = ((performance.now()-t0)/1000).toFixed(2);
    if (!res.ok) throw new Error(`HTTP ${{res.status}}`);
    done++;
    if (done % 10 === 0) log(`... ${{done}}/${{items.length}} OK`);
    upd(done, items.length);
  }}

  async function worker() {{
    while (queue.length) {{
      const it = queue.shift();
      try {{ await uploadOne(it); }}
      catch(e) {{ ko++; log("FAIL "+it.rel+" :: "+(e && e.message?e.message:e)); done++; upd(done, items.length); }}
    }}
  }}

  await Promise.all(Array.from({{length:K}}, worker));
  log(`Termin√© ‚Äî OK=${{done - ko}}, FAIL=${{ko}}`);

  const target = window.top.location.origin + window.top.location.pathname + "?batch=" + BATCH_ID;
  window.top.location.href = target;
}});
</script>
</body></html>
""", height=380)
    st.stop()
